{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing libraries\n",
    "!pip install tensorflow\n",
    "# Imports\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUS Pills detection model\n",
    "\n",
    "## Explanation of the imports:\n",
    "\n",
    "| Import name | Usage |\n",
    "| - | - |\n",
    "| pathlib.Path | folder/directory management |\n",
    "| tensorflow | creating AI model |\n",
    "| datetime | creating model name |\n",
    "| json | unpacking parameters from file |\n",
    "| os | rising Tensorflow min log level |\n",
    "\n",
    "## Clearing unnecessary warnings caused by Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model save thresholds\n",
    "MAX_LOSS = 0.5\n",
    "MIN_ACC = 0.9\n",
    "\n",
    "# Verbose level\n",
    "VERBOSE = 2\n",
    "\n",
    "# Directories\n",
    "DATA_DIR = \"..\\\\data\\\\images\\\\.train\"\n",
    "SAVE_DIR = \".\\\\models\"\n",
    "LOG_DIR = \".\\\\.logs\"\n",
    "\n",
    "# Files\n",
    "PARAMETERS_F = \".\\\\parameters\\\\parameters_list.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_model function:\n",
    "\n",
    "Create a package (model, test dataset, train dataset, batch_size, learning rate, epochs). Use the predefined dictionary with desired parameters. Every dictionary should look like that:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"input_y\": <integer>,\n",
    "    \"input_x\": <integer>,\n",
    "    \"batch_size\": <integer>,\n",
    "    \"dimensions\": <integer>,\n",
    "    \"conv_filters\": <list of integers>,\n",
    "    \"dense_units\": <list of integers>,\n",
    "    \"drop_prob\": <list of floats>,\n",
    "    \"learning_rate\": <float>,\n",
    "    \"epochs\": <integer>\n",
    "}\n",
    "```\n",
    "\n",
    "This script already uses a pre-existing ```*.json``` file with a list of directories used by the ```map()``` function by the end of this script. You can edit it to create different models. Core features of models are static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_package(params: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Load dataset and create the model based on given parameters.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\" SET VARIABLES \"\"\"\n",
    "    # Number of pill types we want the model to be albe to predict\n",
    "    outputs = len(list(Path(DATA_DIR).iterdir()))\n",
    "\n",
    "    # Inputs: y = height, x = width\n",
    "    input_y = params['input_y']\n",
    "    input_x = params['input_x']\n",
    "\n",
    "    # Batch size, learning rate, and epochs\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    epochs = params['epochs']\n",
    "\n",
    "    # Dimensions and color mode\n",
    "    dimensions = params['dimensions']\n",
    "    if dimensions == 1:\n",
    "        color_mode = 'grayscale'\n",
    "    elif dimensions == 3:\n",
    "        color_mode = 'rgb'\n",
    "    \n",
    "    # Convolution filters, dense units, and dropout probability\n",
    "    filters_list = params['conv_filters']\n",
    "    dense_block = zip(params['dense_units'], params['drop_prob'])\n",
    "\n",
    "    # Regularizer used for convolutions\n",
    "    regul_l2 = tf.keras.regularizers.L2()\n",
    "\n",
    "\n",
    "    \"\"\" LOAD DATASET \"\"\"\n",
    "    ds_train, ds_test = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=DATA_DIR,\n",
    "        label_mode=\"int\",\n",
    "        batch_size=batch_size,\n",
    "        image_size=(input_y, input_x),\n",
    "        validation_split=0.2,\n",
    "        seed=123,\n",
    "        subset=\"both\",\n",
    "        color_mode=color_mode,\n",
    "    )\n",
    "\n",
    "\n",
    "    \"\"\" CREATE MODEL \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add input layer\n",
    "    model.add(tf.keras.layers.Input((input_y, input_x, dimensions)))\n",
    "\n",
    "    # Add conv2d, maxpool, and batchnorm layers\n",
    "    for filters in filters_list:\n",
    "        model.add(tf.keras.layers.Conv2D(filters, kernel_size=3,\n",
    "                  padding='same', activation='relu', kernel_regularizer=regul_l2))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=5, padding='same'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # Add flatten layer\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Add dense and dropout layers\n",
    "    for units, drop_prob in dense_block:\n",
    "        model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(rate=drop_prob))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(tf.keras.layers.Dense(outputs, activation='relu'))\n",
    "\n",
    "\n",
    "    \"\"\" CREATE A PACKAGE \"\"\"\n",
    "    package = {\n",
    "        'model': model,\n",
    "        'train': ds_train,\n",
    "        'test': ds_test,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'epochs': epochs,\n",
    "    }\n",
    "\n",
    "    return package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the parameters from the file and map all of its contents to create packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PARAMETERS_F, 'r') as f:\n",
    "    parameters_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 796 files belonging to 15 classes.\n",
      "Using 637 files for training.\n",
      "Using 159 files for validation.\n"
     ]
    }
   ],
   "source": [
    "packages = list(map(create_package, parameters_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, evaluate, and save the model extracted from every package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 50)        1400      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 50)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 13, 13, 50)       200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 100)       45100     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 100)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 3, 3, 100)        400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 900)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               90100     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                1515      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,715\n",
      "Trainable params: 138,415\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "43/43 - 10s - loss: 3.0750 - accuracy: 0.2732 - 10s/epoch - 239ms/step\n",
      "Epoch 2/100\n",
      "43/43 - 6s - loss: 2.4847 - accuracy: 0.4474 - 6s/epoch - 141ms/step\n",
      "Epoch 3/100\n",
      "43/43 - 6s - loss: 2.1016 - accuracy: 0.5495 - 6s/epoch - 139ms/step\n",
      "Epoch 4/100\n",
      "43/43 - 5s - loss: 1.8537 - accuracy: 0.6342 - 5s/epoch - 118ms/step\n",
      "Epoch 5/100\n",
      "43/43 - 5s - loss: 1.7397 - accuracy: 0.6327 - 5s/epoch - 124ms/step\n",
      "Epoch 6/100\n",
      "43/43 - 6s - loss: 1.5768 - accuracy: 0.6813 - 6s/epoch - 132ms/step\n",
      "Epoch 7/100\n",
      "43/43 - 5s - loss: 1.4582 - accuracy: 0.7080 - 5s/epoch - 108ms/step\n",
      "Epoch 8/100\n",
      "43/43 - 5s - loss: 1.4288 - accuracy: 0.7331 - 5s/epoch - 113ms/step\n",
      "Epoch 9/100\n",
      "43/43 - 5s - loss: 1.2970 - accuracy: 0.7567 - 5s/epoch - 114ms/step\n",
      "Epoch 10/100\n",
      "43/43 - 5s - loss: 1.2076 - accuracy: 0.7849 - 5s/epoch - 125ms/step\n",
      "Epoch 11/100\n",
      "43/43 - 5s - loss: 1.2117 - accuracy: 0.7645 - 5s/epoch - 109ms/step\n",
      "Epoch 12/100\n",
      "43/43 - 6s - loss: 1.1760 - accuracy: 0.7755 - 6s/epoch - 134ms/step\n",
      "Epoch 13/100\n",
      "43/43 - 7s - loss: 1.1178 - accuracy: 0.7928 - 7s/epoch - 166ms/step\n",
      "Epoch 14/100\n",
      "43/43 - 6s - loss: 1.0453 - accuracy: 0.8132 - 6s/epoch - 148ms/step\n",
      "Epoch 15/100\n",
      "43/43 - 5s - loss: 0.9142 - accuracy: 0.8619 - 5s/epoch - 126ms/step\n",
      "Epoch 16/100\n",
      "43/43 - 5s - loss: 0.9144 - accuracy: 0.8462 - 5s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "43/43 - 6s - loss: 0.9303 - accuracy: 0.8320 - 6s/epoch - 130ms/step\n",
      "Epoch 18/100\n",
      "43/43 - 5s - loss: 0.8321 - accuracy: 0.8697 - 5s/epoch - 126ms/step\n",
      "Epoch 19/100\n",
      "43/43 - 5s - loss: 0.7949 - accuracy: 0.8838 - 5s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "43/43 - 5s - loss: 0.7472 - accuracy: 0.8870 - 5s/epoch - 124ms/step\n",
      "Epoch 21/100\n",
      "43/43 - 6s - loss: 0.7683 - accuracy: 0.8870 - 6s/epoch - 130ms/step\n",
      "Epoch 22/100\n",
      "43/43 - 5s - loss: 0.7615 - accuracy: 0.8776 - 5s/epoch - 128ms/step\n",
      "Epoch 23/100\n",
      "43/43 - 5s - loss: 0.7212 - accuracy: 0.8870 - 5s/epoch - 124ms/step\n",
      "Epoch 24/100\n",
      "43/43 - 5s - loss: 0.7156 - accuracy: 0.8995 - 5s/epoch - 118ms/step\n",
      "Epoch 25/100\n",
      "43/43 - 6s - loss: 0.6572 - accuracy: 0.9042 - 6s/epoch - 129ms/step\n",
      "Epoch 26/100\n",
      "43/43 - 5s - loss: 0.6645 - accuracy: 0.9089 - 5s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "43/43 - 5s - loss: 0.6565 - accuracy: 0.9137 - 5s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "43/43 - 5s - loss: 0.6227 - accuracy: 0.9215 - 5s/epoch - 127ms/step\n",
      "Epoch 29/100\n",
      "43/43 - 5s - loss: 0.6521 - accuracy: 0.9011 - 5s/epoch - 124ms/step\n",
      "Epoch 30/100\n",
      "43/43 - 5s - loss: 0.6104 - accuracy: 0.9246 - 5s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "43/43 - 5s - loss: 0.5719 - accuracy: 0.9341 - 5s/epoch - 127ms/step\n",
      "Epoch 32/100\n",
      "43/43 - 5s - loss: 0.6305 - accuracy: 0.9042 - 5s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "43/43 - 5s - loss: 0.5885 - accuracy: 0.9246 - 5s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "43/43 - 5s - loss: 0.5677 - accuracy: 0.9262 - 5s/epoch - 127ms/step\n",
      "Epoch 35/100\n",
      "43/43 - 5s - loss: 0.5857 - accuracy: 0.9325 - 5s/epoch - 123ms/step\n",
      "Epoch 36/100\n",
      "43/43 - 5s - loss: 0.5724 - accuracy: 0.9278 - 5s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "43/43 - 6s - loss: 0.6538 - accuracy: 0.8870 - 6s/epoch - 128ms/step\n",
      "Epoch 38/100\n",
      "43/43 - 5s - loss: 0.5782 - accuracy: 0.9309 - 5s/epoch - 123ms/step\n",
      "Epoch 39/100\n",
      "43/43 - 5s - loss: 0.5224 - accuracy: 0.9482 - 5s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "43/43 - 5s - loss: 0.5023 - accuracy: 0.9529 - 5s/epoch - 126ms/step\n",
      "Epoch 41/100\n",
      "43/43 - 6s - loss: 0.5095 - accuracy: 0.9388 - 6s/epoch - 134ms/step\n",
      "Epoch 42/100\n",
      "43/43 - 5s - loss: 0.5066 - accuracy: 0.9513 - 5s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "43/43 - 5s - loss: 0.4622 - accuracy: 0.9639 - 5s/epoch - 126ms/step\n",
      "Epoch 44/100\n",
      "43/43 - 5s - loss: 0.4722 - accuracy: 0.9576 - 5s/epoch - 123ms/step\n",
      "Epoch 45/100\n",
      "43/43 - 5s - loss: 0.4375 - accuracy: 0.9686 - 5s/epoch - 119ms/step\n",
      "Epoch 46/100\n",
      "43/43 - 5s - loss: 0.4375 - accuracy: 0.9608 - 5s/epoch - 125ms/step\n",
      "Epoch 47/100\n",
      "43/43 - 5s - loss: 0.4395 - accuracy: 0.9623 - 5s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "43/43 - 5s - loss: 0.4350 - accuracy: 0.9749 - 5s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "43/43 - 5s - loss: 0.4073 - accuracy: 0.9670 - 5s/epoch - 125ms/step\n",
      "Epoch 50/100\n",
      "43/43 - 5s - loss: 0.4646 - accuracy: 0.9482 - 5s/epoch - 127ms/step\n",
      "Epoch 51/100\n",
      "43/43 - 5s - loss: 0.5524 - accuracy: 0.9199 - 5s/epoch - 119ms/step\n",
      "Epoch 52/100\n",
      "43/43 - 5s - loss: 0.5287 - accuracy: 0.9388 - 5s/epoch - 126ms/step\n",
      "Epoch 53/100\n",
      "43/43 - 5s - loss: 0.5407 - accuracy: 0.9309 - 5s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "43/43 - 5s - loss: 0.4797 - accuracy: 0.9576 - 5s/epoch - 119ms/step\n",
      "Epoch 55/100\n",
      "43/43 - 6s - loss: 0.4838 - accuracy: 0.9545 - 6s/epoch - 128ms/step\n",
      "Epoch 56/100\n",
      "43/43 - 6s - loss: 0.4854 - accuracy: 0.9466 - 6s/epoch - 131ms/step\n",
      "Epoch 57/100\n",
      "43/43 - 5s - loss: 0.4763 - accuracy: 0.9576 - 5s/epoch - 123ms/step\n",
      "Epoch 58/100\n",
      "43/43 - 5s - loss: 0.5035 - accuracy: 0.9372 - 5s/epoch - 125ms/step\n",
      "Epoch 59/100\n",
      "43/43 - 6s - loss: 0.4585 - accuracy: 0.9655 - 6s/epoch - 133ms/step\n",
      "Epoch 60/100\n",
      "43/43 - 5s - loss: 0.4364 - accuracy: 0.9733 - 5s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "43/43 - 5s - loss: 0.4421 - accuracy: 0.9608 - 5s/epoch - 125ms/step\n",
      "Epoch 62/100\n",
      "43/43 - 5s - loss: 0.4971 - accuracy: 0.9403 - 5s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "43/43 - 5s - loss: 0.4538 - accuracy: 0.9529 - 5s/epoch - 126ms/step\n",
      "Epoch 64/100\n",
      "43/43 - 6s - loss: 0.4427 - accuracy: 0.9655 - 6s/epoch - 141ms/step\n",
      "Epoch 65/100\n",
      "43/43 - 5s - loss: 0.4461 - accuracy: 0.9529 - 5s/epoch - 125ms/step\n",
      "Epoch 66/100\n",
      "43/43 - 5s - loss: 0.4365 - accuracy: 0.9655 - 5s/epoch - 124ms/step\n",
      "Epoch 67/100\n",
      "43/43 - 6s - loss: 0.4034 - accuracy: 0.9686 - 6s/epoch - 140ms/step\n",
      "Epoch 68/100\n",
      "43/43 - 6s - loss: 0.2794 - accuracy: 0.9655 - 6s/epoch - 144ms/step\n",
      "Epoch 69/100\n",
      "43/43 - 6s - loss: 0.2637 - accuracy: 0.9686 - 6s/epoch - 137ms/step\n",
      "Epoch 70/100\n",
      "43/43 - 6s - loss: 0.2627 - accuracy: 0.9655 - 6s/epoch - 129ms/step\n",
      "Epoch 71/100\n",
      "43/43 - 5s - loss: 0.2623 - accuracy: 0.9702 - 5s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "43/43 - 5s - loss: 0.2495 - accuracy: 0.9780 - 5s/epoch - 118ms/step\n",
      "Epoch 73/100\n",
      "43/43 - 5s - loss: 0.2509 - accuracy: 0.9733 - 5s/epoch - 127ms/step\n",
      "Epoch 74/100\n",
      "43/43 - 5s - loss: 0.2265 - accuracy: 0.9749 - 5s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "43/43 - 5s - loss: 0.2458 - accuracy: 0.9749 - 5s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "43/43 - 6s - loss: 0.2663 - accuracy: 0.9749 - 6s/epoch - 137ms/step\n",
      "Epoch 77/100\n",
      "43/43 - 5s - loss: 0.2773 - accuracy: 0.9560 - 5s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "43/43 - 5s - loss: 0.2941 - accuracy: 0.9560 - 5s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "43/43 - 6s - loss: 0.2400 - accuracy: 0.9827 - 6s/epoch - 129ms/step\n",
      "Epoch 80/100\n",
      "43/43 - 5s - loss: 0.1968 - accuracy: 0.9890 - 5s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "43/43 - 5s - loss: 0.2227 - accuracy: 0.9827 - 5s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "43/43 - 5s - loss: 0.2581 - accuracy: 0.9702 - 5s/epoch - 127ms/step\n",
      "Epoch 83/100\n",
      "43/43 - 5s - loss: 0.3339 - accuracy: 0.9419 - 5s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "43/43 - 5s - loss: 0.3454 - accuracy: 0.9451 - 5s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "43/43 - 5s - loss: 0.2516 - accuracy: 0.9733 - 5s/epoch - 126ms/step\n",
      "Epoch 86/100\n",
      "43/43 - 5s - loss: 0.2065 - accuracy: 0.9906 - 5s/epoch - 123ms/step\n",
      "Epoch 87/100\n",
      "43/43 - 5s - loss: 0.1915 - accuracy: 0.9906 - 5s/epoch - 119ms/step\n",
      "Epoch 88/100\n",
      "43/43 - 6s - loss: 0.1802 - accuracy: 0.9922 - 6s/epoch - 129ms/step\n",
      "Epoch 89/100\n",
      "43/43 - 6s - loss: 0.2138 - accuracy: 0.9827 - 6s/epoch - 130ms/step\n",
      "Epoch 90/100\n",
      "43/43 - 5s - loss: 0.2446 - accuracy: 0.9796 - 5s/epoch - 124ms/step\n",
      "Epoch 91/100\n",
      "43/43 - 6s - loss: 0.2308 - accuracy: 0.9733 - 6s/epoch - 128ms/step\n",
      "Epoch 92/100\n",
      "43/43 - 5s - loss: 0.2649 - accuracy: 0.9670 - 5s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "43/43 - 5s - loss: 0.3042 - accuracy: 0.9451 - 5s/epoch - 118ms/step\n",
      "Epoch 94/100\n",
      "43/43 - 5s - loss: 0.3695 - accuracy: 0.9341 - 5s/epoch - 124ms/step\n",
      "Epoch 95/100\n",
      "43/43 - 5s - loss: 0.2937 - accuracy: 0.9639 - 5s/epoch - 119ms/step\n",
      "Epoch 96/100\n",
      "43/43 - 5s - loss: 0.2221 - accuracy: 0.9859 - 5s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "43/43 - 6s - loss: 0.1835 - accuracy: 0.9969 - 6s/epoch - 136ms/step\n",
      "Epoch 98/100\n",
      "43/43 - 5s - loss: 0.1779 - accuracy: 0.9937 - 5s/epoch - 119ms/step\n",
      "Epoch 99/100\n",
      "43/43 - 5s - loss: 0.1649 - accuracy: 0.9969 - 5s/epoch - 124ms/step\n",
      "Epoch 100/100\n",
      "43/43 - 5s - loss: 0.1550 - accuracy: 0.9984 - 5s/epoch - 126ms/step\n",
      "11/11 - 1s - loss: 0.5961 - accuracy: 0.8805 - 1s/epoch - 111ms/step\n"
     ]
    }
   ],
   "source": [
    "for package in packages:\n",
    "\n",
    "    # Unpack all variables\n",
    "    model = package['model']\n",
    "    train = package['train']\n",
    "    test = package['test']\n",
    "    batch_size = package['batch_size']\n",
    "    learning_rate = package['learning_rate']\n",
    "    epochs = package['epochs']\n",
    "\n",
    "    # Print the summary\n",
    "    if (VERBOSE == 2):\n",
    "        model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=[tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True)],\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # Create the model's name\n",
    "    model_name = f\"cnn-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "    # logging directory\n",
    "    log_dir = f'{LOG_DIR}\\\\{model_name}'\n",
    "\n",
    "    # Initiate TensorBoard\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Fit the dataset to the model\n",
    "    model.fit(train, batch_size=batch_size, epochs=epochs,\n",
    "              verbose=VERBOSE, callbacks=[tensorboard])\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate = model.evaluate(test, batch_size=batch_size,\n",
    "                              verbose=VERBOSE)\n",
    "\n",
    "    # Save the model if plausible\n",
    "    eval_loss = evaluate[0]\n",
    "    eval_accuracy = evaluate[1]\n",
    "    if (eval_loss < MAX_LOSS) and (eval_accuracy > MIN_ACC):\n",
    "        model.save(f\"{SAVE_DIR}\\\\{model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9fe3a0d77b7f701eeb320c3c30fef7c06fc31f1d1fd5594056fae9442a9540c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
